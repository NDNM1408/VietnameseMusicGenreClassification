{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the logistic regression model\n",
    "logistic_regression_model = joblib.load('logistic_regression_model.pkl')\n",
    "\n",
    "# Load the StandardScaler\n",
    "sc = joblib.load('standard_scaler.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def extract_vocal_segment(audio_file, duration=60, threshold=0.01):\n",
    "    y, sr = librosa.load(audio_file, sr=22050)\n",
    "    vocal_start_time = 30\n",
    "    # Calculate start frame and end frame based on vocal_start_time and duration\n",
    "    start_frame = int(librosa.time_to_samples(vocal_start_time, sr=sr))\n",
    "    end_frame = start_frame + int(sr * duration)\n",
    "\n",
    "    # Ensure the end frame is within the audio length\n",
    "    if end_frame > len(y):\n",
    "        end_frame = len(y)\n",
    "\n",
    "    # Extract the vocal segment\n",
    "    vocal_segment = y[start_frame:end_frame]\n",
    "\n",
    "    return vocal_segment, sr\n",
    "\n",
    "def extract_features(audio_path, num_mfcc=20, sample_rate=22050, n_fft=2048, chroma_hop_length=512):\n",
    "    # Initialize the feature dictionary\n",
    "    features = {\n",
    "        \"filename\": os.path.basename(audio_path),\n",
    "        \"chroma_stft_mean\": 0, \"chroma_stft_var\": 0,\n",
    "        \"rms_mean\": 0, \"rms_var\": 0,\n",
    "        \"spectral_centroid_mean\": 0, \"spectral_centroid_var\": 0,\n",
    "        \"spectral_bandwidth_mean\": 0, \"spectral_bandwidth_var\": 0,\n",
    "        \"rolloff_mean\": 0, \"rolloff_var\": 0,\n",
    "        \"zero_crossing_rate_mean\": 0, \"zero_crossing_rate_var\": 0,\n",
    "        \"harmony_mean\": 0, \"harmony_var\": 0,\n",
    "        \"perceptr_mean\": 0, \"perceptr_var\": 0,\n",
    "        \"tempo\": 0\n",
    "    }\n",
    "\n",
    "    for i in range(1, num_mfcc+1):\n",
    "        features[f\"mfcc{i}_mean\"] = 0\n",
    "        features[f\"mfcc{i}_var\"] = 0\n",
    "\n",
    "    # Extract the vocal segment\n",
    "    vocal_segment, sr = extract_vocal_segment(audio_path)\n",
    "\n",
    "    # Chromagram\n",
    "    chromagram = librosa.feature.chroma_stft(y=vocal_segment, sr=sr, hop_length=chroma_hop_length)\n",
    "    features[\"chroma_stft_mean\"] = chromagram.mean()\n",
    "    features[\"chroma_stft_var\"] = chromagram.var()\n",
    "    \n",
    "    # Root Mean Square Energy\n",
    "    RMSEn = librosa.feature.rms(y=vocal_segment)\n",
    "    features[\"rms_mean\"] = RMSEn.mean()\n",
    "    features[\"rms_var\"] = RMSEn.var()\n",
    "    \n",
    "    # Spectral Centroid\n",
    "    spec_cent = librosa.feature.spectral_centroid(y=vocal_segment)\n",
    "    features[\"spectral_centroid_mean\"] = spec_cent.mean()\n",
    "    features[\"spectral_centroid_var\"] = spec_cent.var()\n",
    "    \n",
    "    # Spectral Bandwidth\n",
    "    spec_band = librosa.feature.spectral_bandwidth(y=vocal_segment, sr=sr)\n",
    "    features[\"spectral_bandwidth_mean\"] = spec_band.mean()\n",
    "    features[\"spectral_bandwidth_var\"] = spec_band.var()\n",
    "    \n",
    "    # Rolloff\n",
    "    spec_roll = librosa.feature.spectral_rolloff(y=vocal_segment, sr=sr)\n",
    "    features[\"rolloff_mean\"] = spec_roll.mean()\n",
    "    features[\"rolloff_var\"] = spec_roll.var()\n",
    "    \n",
    "    # Zero Crossing Rate\n",
    "    zero_crossing = librosa.feature.zero_crossing_rate(y=vocal_segment)\n",
    "    features[\"zero_crossing_rate_mean\"] = zero_crossing.mean()\n",
    "    features[\"zero_crossing_rate_var\"] = zero_crossing.var()\n",
    "    \n",
    "    # Harmonics and Percussive\n",
    "    harmony, perceptr = librosa.effects.hpss(y=vocal_segment)\n",
    "    features[\"harmony_mean\"] = harmony.mean()\n",
    "    features[\"harmony_var\"] = harmony.var()\n",
    "    features[\"perceptr_mean\"] = perceptr.mean()\n",
    "    features[\"perceptr_var\"] = perceptr.var()\n",
    "    \n",
    "    # Tempo\n",
    "    tempo, _ = librosa.beat.beat_track(y=vocal_segment, sr=sr)\n",
    "    features[\"tempo\"] = float(tempo)\n",
    "    \n",
    "    # MFCCs\n",
    "    mfcc = librosa.feature.mfcc(y=vocal_segment, sr=sr, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=chroma_hop_length)\n",
    "    mfcc = mfcc.T\n",
    "    for x in range(num_mfcc):\n",
    "        features[f\"mfcc{x+1}_mean\"] = mfcc[:, x].mean()\n",
    "        features[f\"mfcc{x+1}_var\"] = mfcc[:, x].var()\n",
    "    \n",
    "    return features\n",
    "\n",
    "def predict_genre(audio_path):\n",
    "    # Extract features from the audio file\n",
    "    features = extract_features(audio_path)\n",
    "    \n",
    "    # Prepare the feature vector for prediction\n",
    "    feature_vector = [features[feat] for feat in features if feat not in [\"filename\", \"label\"]]\n",
    "    feature_vector = np.array(feature_vector).reshape(1, -1)\n",
    "    \n",
    "    # Normalize the feature vector using StandardScaler\n",
    "    feature_vector_normalized = sc.transform(feature_vector)\n",
    "    \n",
    "    # Predict the genre using the provided model\n",
    "    prediction = logistic_regression_model.predict(feature_vector_normalized)\n",
    "    \n",
    "    # Map numerical label to genre name\n",
    "    genre_mapping = {\n",
    "        0: 'bolero',\n",
    "        1: 'hiphop',\n",
    "        2: 'kid',\n",
    "        3: 'rb',\n",
    "        4: 'red',\n",
    "        5: 'rock'\n",
    "    }\n",
    "    \n",
    "    predicted_genre = genre_mapping[prediction[0]]\n",
    "    \n",
    "    return predicted_genre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted genre is: rock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_18776\\2944324134.py:83: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  features[\"tempo\"] = float(tempo)\n"
     ]
    }
   ],
   "source": [
    "# Example audio file path\n",
    "audio_path = \"4_Ánh Đèn Phố.wav\"\n",
    "\n",
    "# Predict genre\n",
    "predicted_genre = predict_genre(audio_path)\n",
    "print(f\"The predicted genre is: {predicted_genre}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "981d7c869dd2079483315c95b86c039a0bfcee0010f0840c07f83e4c693b861d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
